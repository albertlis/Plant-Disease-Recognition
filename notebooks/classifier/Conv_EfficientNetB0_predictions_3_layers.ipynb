{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv EfficientNetB0 predictions 3 layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertlis/Plant-Disease-Recognition/blob/main/notebooks/classifier/Conv_EfficientNetB0_predictions_3_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pce5jvbclOPW",
        "outputId": "9f23c907-fb74-419d-ed24-80cce5bf9dda"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "drive.mount(\"/content/drive\")\r\n",
        "!unzip -q /content/drive/My\\ Drive/PDR/Data/original.zip -d /content\r\n",
        "!rm -r sample_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AlVLxvHpfhS"
      },
      "source": [
        "Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3IjN0-opjqy"
      },
      "source": [
        "img_shape = (224, 224, 3)\r\n",
        "e_net_out_shape = (7, 7, 1280)\r\n",
        "nr_of_imgs = 49940\r\n",
        "nr_of_val_imgs = 3862\r\n",
        "batch_size = 64\r\n",
        "nr_of_classes = 39\r\n",
        "train_path = './original/train'\r\n",
        "val_path = './original/val'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3id7bkG0UYXP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po0ue1sBoq_E"
      },
      "source": [
        "Get predictions from Convolutional part to fast train classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjlpB0lflqj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523fe381-0941-4aa5-e242-105c5a312a70"
      },
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "e_net = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=img_shape)\r\n",
        "\r\n",
        "def make_conv_predictions():\r\n",
        "    gen = ImageDataGenerator(rotation_range=45, horizontal_flip=True, vertical_flip=True, rescale=1/255)\r\n",
        "    datagen = gen.flow_from_directory(train_path, target_size=img_shape[:2], batch_size=batch_size, class_mode='categorical')\r\n",
        "    val_datagen = gen.flow_from_directory(val_path, target_size=img_shape[:2], batch_size=batch_size, class_mode='categorical')\r\n",
        "\r\n",
        "    imgs = np.lib.format.open_memmap('imgs.npy', dtype='float32', mode='w+', shape=((nr_of_imgs,) + e_net_out_shape))\r\n",
        "    labels = np.lib.format.open_memmap('labels.npy', dtype='uint8', mode='w+', shape=(nr_of_imgs, nr_of_classes))\r\n",
        "    val_imgs = np.lib.format.open_memmap('val_imgs.npy', dtype='float32', mode='w+', shape=((nr_of_val_imgs,) + e_net_out_shape))\r\n",
        "    val_labels = np.lib.format.open_memmap('val_labels.npy', dtype='uint8', mode='w+', shape=(nr_of_val_imgs, nr_of_classes))\r\n",
        "\r\n",
        "    for i, (imgs_batch, labels_batch) in enumerate(datagen):\r\n",
        "        count = i * batch_size\r\n",
        "        line = ' '\r\n",
        "        if not i % 20 and i != 0:\r\n",
        "            line = '\\n'\r\n",
        "        print(f'%5d{line}' %(count), end='')\r\n",
        "        if count > nr_of_imgs:\r\n",
        "            break\r\n",
        "        predictions = e_net.predict(imgs_batch)\r\n",
        "        imgs[count : count + batch_size] = predictions\r\n",
        "        labels[count : count + batch_size] = labels_batch\r\n",
        "    print()\r\n",
        "\r\n",
        "    for i, (imgs_batch, labels_batch) in enumerate(val_datagen):\r\n",
        "        count = i * batch_size\r\n",
        "        line = ' '\r\n",
        "        if not i % 20 and i != 0:\r\n",
        "            line = '\\n'\r\n",
        "        print(f'%5d{line}' %(count), end='')\r\n",
        "        if count > nr_of_val_imgs:\r\n",
        "            break\r\n",
        "        predictions = e_net.predict(imgs_batch)\r\n",
        "        val_imgs[count : count + batch_size] = predictions\r\n",
        "        val_labels[count : count + batch_size] = labels_batch\r\n",
        "    print()\r\n",
        "    \r\n",
        "make_conv_predictions()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "Found 49940 images belonging to 39 classes.\n",
            "Found 3862 images belonging to 39 classes.\n",
            "    0   512  1024  1536  2048  2560  3072  3584  4096  4608  5120  5632  6144  6656  7168  7680  8192  8704  9216  9728 10240\n",
            "10752 11264 11776 12288 12800 13312 13824 14336 14848 15360 15872 16384 16896 17408 17920 18432 18944 19456 19968 20480\n",
            "20992 21504 22016 22528 23040 23552 24064 24576 25088 25600 26112 26624 27136 27648 28160 28672 29184 29696 30208 30720\n",
            "31232 31744 32256 32768 33280 33792 34304 34816 35328 35840 36352 36864 37376 37888 38400 38912 39424 39936 40448 40960\n",
            "41472 41984 42496 43008 43520 44032 44544 45056 45568 46080 46592 47104 47616 48128 48640 49152 49664 50176 \n",
            "    0   512  1024  1536  2048  2560  3072  3584  4096 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZyghXul69Ws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a47d342-ae41-4be7-c2f4-e7d906fe7498"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Flatten, InputLayer, BatchNormalization, Dropout\r\n",
        "import tensorflow.keras.callbacks as clb\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras import backend as K \r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "\r\n",
        "def build_model():\r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    model.add(InputLayer(input_shape=e_net_out_shape))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(Dense(867, activation='relu'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(Dense(453, activation='relu'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(Dense(39, activation='softmax'))\r\n",
        "\r\n",
        "    model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['acc'])\r\n",
        "    return model\r\n",
        "\r\n",
        "def np_array_memmap_gen(feat_path, label_path, batch_size=128, shuffle_array=True):\r\n",
        "    while 1:\r\n",
        "        x = np.load(feat_path, mmap_mode='r')\r\n",
        "        y = np.load(label_path, mmap_mode='r')\r\n",
        "        lst = [i for i in range(x.shape[0])]\r\n",
        "\r\n",
        "        if shuffle_array:\r\n",
        "            random.shuffle(lst)\r\n",
        "\r\n",
        "        iters = len(lst) // batch_size + 1\r\n",
        "\r\n",
        "        for i in range(iters):\r\n",
        "            start = i * batch_size\r\n",
        "            end = (i + 1) * batch_size\r\n",
        "            yield (x[lst[start : end]], y[lst[start : end]])\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "            clb.ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_lr=1e-7, patience=2, verbose=1),\r\n",
        "            clb.EarlyStopping(monitor='val_acc', patience=4, verbose=1),\r\n",
        "            clb.ModelCheckpoint(monitor='val_acc', filepath='/content/drive/My Drive/PDR/Results/models/external_fast_model.h5',\r\n",
        "                                save_best_only=True, verbose=1)\r\n",
        "            ]\r\n",
        "\r\n",
        "train_gen = np_array_memmap_gen('imgs.npy', 'labels.npy', batch_size=batch_size)\r\n",
        "val_gen = np_array_memmap_gen('val_imgs.npy', 'val_labels.npy', batch_size=batch_size)\r\n",
        "\r\n",
        "train_steps = nr_of_imgs // batch_size + 1\r\n",
        "val_steps = nr_of_val_imgs // batch_size + 1\r\n",
        "\r\n",
        "model = build_model()\r\n",
        "\r\n",
        "history = model.fit(train_gen, epochs=50, validation_data=val_gen, callbacks=callbacks, verbose=1, \r\n",
        "                    steps_per_epoch=train_steps, validation_steps=val_steps)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 2.8159 - acc: 0.2740 - val_loss: 2.0163 - val_acc: 0.3791\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.37908, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 2/50\n",
            "781/781 [==============================] - 675s 866ms/step - loss: 1.7636 - acc: 0.4706 - val_loss: 1.7905 - val_acc: 0.4858\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.37908 to 0.48576, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 3/50\n",
            "781/781 [==============================] - 674s 864ms/step - loss: 1.5743 - acc: 0.5210 - val_loss: 4.6526 - val_acc: 0.4143\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.48576\n",
            "Epoch 4/50\n",
            "781/781 [==============================] - 665s 852ms/step - loss: 1.4361 - acc: 0.5629 - val_loss: 4.0204 - val_acc: 0.2683\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.48576\n",
            "Epoch 5/50\n",
            "781/781 [==============================] - 667s 855ms/step - loss: 1.2751 - acc: 0.6103 - val_loss: 0.9153 - val_acc: 0.7289\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.48576 to 0.72890, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 6/50\n",
            "781/781 [==============================] - 673s 863ms/step - loss: 1.1906 - acc: 0.6317 - val_loss: 0.9244 - val_acc: 0.7336\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.72890 to 0.73356, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 7/50\n",
            "781/781 [==============================] - 677s 868ms/step - loss: 1.1436 - acc: 0.6457 - val_loss: 1.0367 - val_acc: 0.7470\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.73356 to 0.74702, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 8/50\n",
            "781/781 [==============================] - 663s 850ms/step - loss: 1.1102 - acc: 0.6564 - val_loss: 0.8503 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.74702 to 0.75013, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 9/50\n",
            "781/781 [==============================] - 664s 851ms/step - loss: 1.0558 - acc: 0.6720 - val_loss: 0.7950 - val_acc: 0.7556\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.75013 to 0.75557, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 10/50\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 1.0355 - acc: 0.6804 - val_loss: 3.3149 - val_acc: 0.7470\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.75557\n",
            "Epoch 11/50\n",
            "781/781 [==============================] - 639s 819ms/step - loss: 1.0023 - acc: 0.6890 - val_loss: 0.7424 - val_acc: 0.7778\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.75557 to 0.77784, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 12/50\n",
            "781/781 [==============================] - 645s 827ms/step - loss: 0.9763 - acc: 0.6940 - val_loss: 1.0023 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.77784\n",
            "Epoch 13/50\n",
            "781/781 [==============================] - 640s 821ms/step - loss: 0.9472 - acc: 0.7054 - val_loss: 3.8537 - val_acc: 0.7830\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.77784 to 0.78301, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 14/50\n",
            "781/781 [==============================] - 637s 816ms/step - loss: 0.9266 - acc: 0.7115 - val_loss: 0.6765 - val_acc: 0.7960\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.78301 to 0.79596, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 15/50\n",
            "781/781 [==============================] - 638s 818ms/step - loss: 0.9044 - acc: 0.7171 - val_loss: 0.6776 - val_acc: 0.7903\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.79596\n",
            "Epoch 16/50\n",
            "781/781 [==============================] - 640s 820ms/step - loss: 0.8774 - acc: 0.7240 - val_loss: 0.7014 - val_acc: 0.7856\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.79596\n",
            "Epoch 17/50\n",
            "781/781 [==============================] - 642s 823ms/step - loss: 0.8498 - acc: 0.7300 - val_loss: 0.6148 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.79596 to 0.81460, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 18/50\n",
            "781/781 [==============================] - 639s 820ms/step - loss: 0.8412 - acc: 0.7344 - val_loss: 0.6408 - val_acc: 0.8042\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.81460\n",
            "Epoch 19/50\n",
            "781/781 [==============================] - 640s 821ms/step - loss: 0.8250 - acc: 0.7430 - val_loss: 0.6009 - val_acc: 0.8213\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.81460 to 0.82134, saving model to /content/drive/My Drive/PDR/Results/models/external_fast_model.h5\n",
            "Epoch 20/50\n",
            "781/781 [==============================] - 645s 826ms/step - loss: 0.8262 - acc: 0.7369 - val_loss: 0.6250 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.82134\n",
            "Epoch 21/50\n",
            "781/781 [==============================] - 643s 824ms/step - loss: 0.8359 - acc: 0.7374 - val_loss: 0.5978 - val_acc: 0.8213\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.82134\n",
            "Epoch 22/50\n",
            "781/781 [==============================] - 643s 824ms/step - loss: 0.8218 - acc: 0.7417 - val_loss: 0.6361 - val_acc: 0.8066\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.82134\n",
            "Epoch 23/50\n",
            "781/781 [==============================] - 639s 820ms/step - loss: 0.8160 - acc: 0.7421 - val_loss: 0.5980 - val_acc: 0.8141\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.82134\n",
            "Epoch 00023: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}